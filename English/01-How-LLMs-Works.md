# ğŸ¤– Language Models: How Do They Work?

LLMs (Large Language Models) are trained on billions of words ğŸ§ ğŸ’¬.  
But the idea of a **language model** came before modern AI â€” it's all about spotting **linguistic patterns**.

ğŸ“Œ Example:  
"I like **pizza**" â†’ whenever we use the verb *like*, it's usually followed by "to" or "of". Thatâ€™s a predictable pattern!

Language models learn these patterns to **predict the next word**, understanding **structures and relationships** between words.

---

# ğŸ§  Word Embeddings

**Word Embeddings** are numeric representations (vectors) of words that capture **semantic similarity**.

ğŸ“ Example:  
Words like "king" and "queen" are close together, just like "cat" and "dog".

They help the model understand **contextual similarity** â€” even between different words.

ğŸ–¼ï¸  
![embeddings](./IMGs/Embeddings.png)  
![word Embedding](./IMGs/Word-Em.png)

---

# ğŸ•¹ï¸ Play with the AI

> â€œLetâ€™s simulate how ChatGPT works!  
For every sentence I write, you reply with the 5 most likely words to complete it â€” along with their probabilities.  
Just the words and probabilities, nothing else.â€

---

## ğŸ”® Predicting the Next Word

At each step, the AI
